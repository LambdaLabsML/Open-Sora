# Que Sora, Sora -Â Whatever Bricks you Build

Welcome to the tutorial for this brick video project!
This guide will walk you through the steps needed to install the necessary dependencies, prepare the dataset, train the model, and run inferences on Lambda's 1-Click Cluster. Let's get started!

## Example Outputs
Below are some example outputs generated by the model, trained as described in this tutorial.
<div align="center">
  <table>
    <tr>
      <td><img src="path/to/video1.gif" width="360" height="540" alt="Example Output 1"/></td>
      <td><img src="path/to/video2.gif" width="360" height="540" alt="Example Output 2"/></td>
      <td><img src="path/to/video3.gif" width="360" height="540" alt="Example Output 3"/></td>
    </tr>
    <tr>
      <td><img src="path/to/video4.gif" width="360" height="540" alt="Example Output 4"/></td>
      <td><img src="path/to/video5.gif" width="360" height="540" alt="Example Output 5"/></td>
      <td><img src="path/to/video6.gif" width="360" height="540" alt="Example Output 6"/></td>
    </tr>
  </table>
</div>


## Introduction
This repository is a fork of [hpcaitech/Open-Sora](https://github.com/hpcaitech/Open-Sora).
Changes include:
- Configs to reproduce fine-tuning on our [brick dataset](https://lambdaml.s3.us-west-1.amazonaws.com/brick.zip).
- Wandb logging of validation outputs
- Cosine Warmup Learning Rate Scheduling
- Several bugfixes (see our [commits](../../commits/lambda_bricks/))


## Installation / Setup
To get started with this project, follow these installation steps:
1. Make sure miniconda is installed by testing the following command
    ```bash
    conda init
    ```
2. **Download the Installer**
   ```bash
   wget https://raw.githubusercontent.com/LambdaLabsML/Open-Sora/lambda_bricks/install.sh
   yes | bash install.sh
   ```
3. **Verify the Installation**:
    The following command should print out `SUCCESS` if your environment is set up correctly.
    ```bash
    cd Open-Sora
    python install-check.py
    ```
4. **Activate Environment**:
    Activate the environment before any of the actions listed below.
    ```bash
    conda activate "brick-osora"
    ```



## Dataset Preparation
To use our demo dataset:
1. Download `bricks.zip` [here](https://lambdaml.s3.us-west-1.amazonaws.com/brick.zip) and unzip it's content into the `Open-Sora` folder.
    ```bash
    unzip bricks.zip
    unzip brick/brick_clips.zip
    ```
    This should have unzipped 1000 mp4 files into `./brick_clips`.
2. Verify that the paths match the demo-csv file for this dataset named `Open-Sora/brick_clips.csv` and are accessible from within the `Open-Sora` folder.

To prepare your own dataset:
1. Setup a Python virtual envrionment using the following script.
    ```bash
    ./scripts/env_setup_data_process.sh
    ```
2. Prepare a `video_urls.txt` file of list of YouTube video links, and run the following data process script.
   ```bash
    python -m scripts.data_process \
    --output /path/where/new/dataset/will/be/created \
    --url-file /path/to/video_urls.txt  \
    --video-dir /path/to/some/videos \
    --prompt video \
    --caption gpt4o \ 
    --num-p 8 \
    --key [OPENAI_API_KEY]
   ```


## Train the Model



```
# For lambdalabs/text2bricks-360p-32f

OMP_NUM_THREADS=52 colossalai run --nproc_per_node 8 \
--hostfile $HOSTFILE \
--master_addr $MASTER_ADDR \
scripts/train.py \
configs/opensora-v1-1/train/text2bricks-360p-32f.py \
--data-path /path/where/dataset/csv/is/located \
--ckpt-path /path/to/OpenSora-STDiT-v2-stage3/model.safetensors

# For lambdalabs/text2bricks-360p-64f

OMP_NUM_THREADS=52 colossalai run --nproc_per_node 8 \
--hostfile $HOSTFILE \
--master_addr $MASTER_ADDR \
scripts/train.py \
configs/opensora-v1-1/train/text2bricks-360p-64f.py \
--data-path /path/where/dataset/csv/is/located \
--ckpt-path /path/to/OpenSora-STDiT-v2-stage3/model.safetensors
```


## Running Inference

```
python scripts/inference.py \
configs/opensora-v1-1/inference/text2bricks-360p-32f.py \
--prompt "A young man walks alone by the seaside." \
--num-frames 32

python scripts/inference.py \
configs/opensora-v1-1/inference/text2bricks-360p-64f.py \
--prompt "A young man walks alone by the seaside." \
--num-frames 64
```

---

Feel free to reach out if you have any questions or encounter any issues. Happy coding!